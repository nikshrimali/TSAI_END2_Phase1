{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd03de9d290524ff883b8259b248a1b147c991642eb880a4d565323a9dbe6df527f",
   "display_name": "Python 3.8.5 64-bit ('AiPy': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\naman\\miniconda3\\envs\\aipy\\lib\\site-packages (1.5.1)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 28, 28]              72\n",
      "              ReLU-2            [-1, 8, 28, 28]               0\n",
      "       BatchNorm2d-3            [-1, 8, 28, 28]              16\n",
      "            Conv2d-4           [-1, 16, 28, 28]           1,152\n",
      "              ReLU-5           [-1, 16, 28, 28]               0\n",
      "       BatchNorm2d-6           [-1, 16, 28, 28]              32\n",
      "            Conv2d-7            [-1, 8, 28, 28]             136\n",
      "         MaxPool2d-8            [-1, 8, 14, 14]               0\n",
      "           Dropout-9            [-1, 8, 14, 14]               0\n",
      "           Conv2d-10            [-1, 8, 14, 14]             576\n",
      "             ReLU-11            [-1, 8, 14, 14]               0\n",
      "      BatchNorm2d-12            [-1, 8, 14, 14]              16\n",
      "           Conv2d-13           [-1, 16, 14, 14]           1,152\n",
      "             ReLU-14           [-1, 16, 14, 14]               0\n",
      "      BatchNorm2d-15           [-1, 16, 14, 14]              32\n",
      "           Conv2d-16            [-1, 8, 14, 14]             136\n",
      "        MaxPool2d-17              [-1, 8, 7, 7]               0\n",
      "          Dropout-18              [-1, 8, 7, 7]               0\n",
      "           Conv2d-19              [-1, 8, 7, 7]             576\n",
      "             ReLU-20              [-1, 8, 7, 7]               0\n",
      "      BatchNorm2d-21              [-1, 8, 7, 7]              16\n",
      "           Conv2d-22             [-1, 16, 7, 7]           1,152\n",
      "             ReLU-23             [-1, 16, 7, 7]               0\n",
      "      BatchNorm2d-24             [-1, 16, 7, 7]              32\n",
      "           Conv2d-25              [-1, 8, 7, 7]             136\n",
      "        MaxPool2d-26              [-1, 8, 3, 3]               0\n",
      "          Dropout-27              [-1, 8, 3, 3]               0\n",
      "           Conv2d-28             [-1, 16, 1, 1]           1,152\n",
      "           Conv2d-29             [-1, 10, 1, 1]             160\n",
      "           Linear-30                   [-1, 20]             400\n",
      "      BatchNorm1d-31                   [-1, 20]              40\n",
      "             ReLU-32                   [-1, 20]               0\n",
      "           Linear-33                   [-1, 19]             380\n",
      "================================================================\n",
      "Total params: 7,364\n",
      "Trainable params: 7,364\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.66\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.69\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from model.mnist_image_plus_random_number import Net\n",
    "import torch \n",
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mon May 17 21:19:02 2021       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 451.48       Driver Version: 451.48       CUDA Version: 11.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1650   WDDM  | 00000000:01:00.0  On |                  N/A |\n| N/A   50C    P8     3W /  N/A |    626MiB /  4096MiB |      3%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|    0   N/A  N/A       536    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n|    0   N/A  N/A      1324    C+G   Insufficient Permissions        N/A      |\n|    0   N/A  N/A      4100    C+G   ...bbwe\\PaintStudio.View.exe    N/A      |\n|    0   N/A  N/A      5140    C+G   ...kyb3d8bbwe\\Calculator.exe    N/A      |\n|    0   N/A  N/A      5152    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n|    0   N/A  N/A      5968    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n|    0   N/A  N/A      6968    C+G   C:\\Windows\\explorer.exe         N/A      |\n|    0   N/A  N/A      8380    C+G   ...8wekyb3d8bbwe\\GameBar.exe    N/A      |\n|    0   N/A  N/A      8504    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n|    0   N/A  N/A      8540    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n|    0   N/A  N/A     10904    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n|    0   N/A  N/A     11684    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n|    0   N/A  N/A     12140    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n|    0   N/A  N/A     12216    C+G   ...b3d8bbwe\\WinStore.App.exe    N/A      |\n|    0   N/A  N/A     13092    C+G   ...ge\\Application\\msedge.exe    N/A      |\n+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from dataloader.mnist_random_digit_dataloader import MnistImageWithRandomNumberDataset as MIRND\n",
    "torch.manual_seed(1)\n",
    "batch_size = 512\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    MIRND(root_directory = './data', train=True,\n",
    "                    transform=[\n",
    "                        transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ]),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    MIRND(root_directory = './data', train=False, transform=[\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ]),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "  model.train()\n",
    "  pbar = tqdm(train_loader, position = 0, leave = True)\n",
    "  mnist_correct = 0\n",
    "  sum_correct = 0\n",
    "  processed = 0\n",
    "  for batch_idx, (data, random_digits, target, sum_of_numbers) in enumerate(pbar):\n",
    "    # get samples\n",
    "    data, random_digits, target, sum_of_numbers = data.to(device), random_digits.to(device), target.to(device), sum_of_numbers.to(device)\n",
    "\n",
    "    # Init\n",
    "    optimizer.zero_grad()\n",
    "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
    "\n",
    "    # Predict\n",
    "    y_pred, sum_pred = model(data, random_digits)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss_digit_detection = F.nll_loss(y_pred, target)\n",
    "    loss_sum_prediction = F.nll_loss(sum_pred, sum_of_numbers)\n",
    "    loss = loss_digit_detection + loss_sum_prediction\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update pbar-tqdm\n",
    "    \n",
    "    mnist_pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "    sum_pred = sum_pred.argmax(dim=1, keepdim=True)\n",
    "    mnist_correct += mnist_pred.eq(target.view_as(mnist_pred)).sum().item()\n",
    "    sum_correct += sum_pred.eq(sum_of_numbers.view_as(sum_pred)).sum().item()\n",
    "    processed += len(data)\n",
    "\n",
    "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Mnist_Accuracy={100*mnist_correct/processed:0.2f} Sum_Accuracy = {100*sum_correct/processed:0.2f}')\n",
    "    train_acc.append(100*mnist_correct+sum_correct/2*processed)\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    mnist_correct = 0\n",
    "    sum_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for (data, random_digits, target, sum_of_numbers) in test_loader:\n",
    "                data, random_digits, target, sum_of_numbers = data.to(device), random_digits.to(device), target.to(device), sum_of_numbers.to(device)\n",
    "                output, sum_pred = model(data, random_digits)\n",
    "                test_loss += F.nll_loss(output, target, reduction='sum').item() + F.nll_loss(sum_pred, sum_of_numbers, reduction='sum').item() # sum up batch loss\n",
    "                mnist_pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "                sum_pred = sum_pred.argmax(dim=1, keepdim=True)\n",
    "                mnist_correct += mnist_pred.eq(target.view_as(mnist_pred)).sum().item()\n",
    "                sum_correct += sum_pred.eq(sum_of_numbers.view_as(sum_pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Mnist Accuracy: {}/{}, Sum Accuracy: {}/{}, Total: ({:.2f}%)\\n'.format(\n",
    "        test_loss, mnist_correct, len(test_loader.dataset), sum_correct, len(test_loader.dataset),\n",
    "        100. * ((mnist_correct + sum_correct) / (2*len(test_loader.dataset)))\n",
    "        ))\n",
    "    \n",
    "    test_acc.append(100. * ((mnist_correct + sum_correct) / (2*len(test_loader.dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/118 [00:00<?, ?it/s]EPOCH -  0\n",
      "Loss=2.506195545196533 Batch_id=117 Mnist_Accuracy=74.59 Sum_Accuracy = 12.73: 100%|██████████| 118/118 [00:15<00:00,  7.68it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 2.4367, Mnist Accuracy: 9587/10000, Sum Accuracy: 1827/10000, Total: (57.07%)\n",
      "\n",
      "EPOCH -  1\n",
      "Loss=1.711471676826477 Batch_id=117 Mnist_Accuracy=95.21 Sum_Accuracy = 36.92: 100%|██████████| 118/118 [00:13<00:00,  8.67it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 1.6883, Mnist Accuracy: 9752/10000, Sum Accuracy: 5252/10000, Total: (75.02%)\n",
      "\n",
      "EPOCH -  2\n",
      "Loss=1.0825353860855103 Batch_id=117 Mnist_Accuracy=96.68 Sum_Accuracy = 61.94: 100%|██████████| 118/118 [00:13<00:00,  8.66it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 1.0337, Mnist Accuracy: 9820/10000, Sum Accuracy: 7781/10000, Total: (88.00%)\n",
      "\n",
      "EPOCH -  3\n",
      "Loss=0.806056797504425 Batch_id=117 Mnist_Accuracy=97.07 Sum_Accuracy = 81.18: 100%|██████████| 118/118 [00:13<00:00,  8.66it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.6894, Mnist Accuracy: 9788/10000, Sum Accuracy: 8857/10000, Total: (93.23%)\n",
      "\n",
      "EPOCH -  4\n",
      "Loss=0.7018200159072876 Batch_id=117 Mnist_Accuracy=97.44 Sum_Accuracy = 90.58: 100%|██████████| 118/118 [00:14<00:00,  8.42it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.4021, Mnist Accuracy: 9834/10000, Sum Accuracy: 9406/10000, Total: (96.20%)\n",
      "\n",
      "EPOCH -  5\n",
      "Loss=0.4122951626777649 Batch_id=117 Mnist_Accuracy=97.89 Sum_Accuracy = 94.55: 100%|██████████| 118/118 [00:13<00:00,  8.64it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.2865, Mnist Accuracy: 9848/10000, Sum Accuracy: 9664/10000, Total: (97.56%)\n",
      "\n",
      "EPOCH -  6\n",
      "Loss=0.34893345832824707 Batch_id=117 Mnist_Accuracy=98.01 Sum_Accuracy = 95.33: 100%|██████████| 118/118 [00:13<00:00,  8.57it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.2309, Mnist Accuracy: 9867/10000, Sum Accuracy: 9739/10000, Total: (98.03%)\n",
      "\n",
      "EPOCH -  7\n",
      "Loss=0.24706289172172546 Batch_id=117 Mnist_Accuracy=98.07 Sum_Accuracy = 95.67: 100%|██████████| 118/118 [00:13<00:00,  8.63it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.2224, Mnist Accuracy: 9861/10000, Sum Accuracy: 9726/10000, Total: (97.94%)\n",
      "\n",
      "EPOCH -  8\n",
      "Loss=0.1865580976009369 Batch_id=117 Mnist_Accuracy=98.11 Sum_Accuracy = 96.01: 100%|██████████| 118/118 [00:13<00:00,  8.58it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1880, Mnist Accuracy: 9882/10000, Sum Accuracy: 9747/10000, Total: (98.15%)\n",
      "\n",
      "EPOCH -  9\n",
      "Loss=0.3953489065170288 Batch_id=117 Mnist_Accuracy=98.22 Sum_Accuracy = 96.23: 100%|██████████| 118/118 [00:13<00:00,  8.68it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1693, Mnist Accuracy: 9883/10000, Sum Accuracy: 9775/10000, Total: (98.29%)\n",
      "\n",
      "EPOCH -  10\n",
      "Loss=0.20822101831436157 Batch_id=117 Mnist_Accuracy=98.42 Sum_Accuracy = 96.79: 100%|██████████| 118/118 [00:13<00:00,  8.64it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1460, Mnist Accuracy: 9889/10000, Sum Accuracy: 9806/10000, Total: (98.47%)\n",
      "\n",
      "EPOCH -  11\n",
      "Loss=0.15742546319961548 Batch_id=117 Mnist_Accuracy=98.37 Sum_Accuracy = 96.84: 100%|██████████| 118/118 [00:13<00:00,  8.50it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1444, Mnist Accuracy: 9893/10000, Sum Accuracy: 9786/10000, Total: (98.39%)\n",
      "\n",
      "EPOCH -  12\n",
      "Loss=0.16167853772640228 Batch_id=117 Mnist_Accuracy=98.44 Sum_Accuracy = 96.97: 100%|██████████| 118/118 [00:13<00:00,  8.55it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1319, Mnist Accuracy: 9898/10000, Sum Accuracy: 9834/10000, Total: (98.66%)\n",
      "\n",
      "EPOCH -  13\n",
      "Loss=0.3649643361568451 Batch_id=117 Mnist_Accuracy=98.50 Sum_Accuracy = 97.10: 100%|██████████| 118/118 [00:13<00:00,  8.64it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1293, Mnist Accuracy: 9914/10000, Sum Accuracy: 9805/10000, Total: (98.59%)\n",
      "\n",
      "EPOCH -  14\n",
      "Loss=0.20613811910152435 Batch_id=117 Mnist_Accuracy=98.45 Sum_Accuracy = 97.09: 100%|██████████| 118/118 [00:13<00:00,  8.66it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1258, Mnist Accuracy: 9910/10000, Sum Accuracy: 9821/10000, Total: (98.66%)\n",
      "\n",
      "EPOCH -  15\n",
      "Loss=0.17535769939422607 Batch_id=117 Mnist_Accuracy=98.61 Sum_Accuracy = 97.23: 100%|██████████| 118/118 [00:13<00:00,  8.62it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1223, Mnist Accuracy: 9907/10000, Sum Accuracy: 9829/10000, Total: (98.68%)\n",
      "\n",
      "EPOCH -  16\n",
      "Loss=0.2709457576274872 Batch_id=117 Mnist_Accuracy=98.62 Sum_Accuracy = 97.38: 100%|██████████| 118/118 [00:13<00:00,  8.59it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1161, Mnist Accuracy: 9910/10000, Sum Accuracy: 9848/10000, Total: (98.79%)\n",
      "\n",
      "EPOCH -  17\n",
      "Loss=0.1500735580921173 Batch_id=117 Mnist_Accuracy=98.67 Sum_Accuracy = 97.37: 100%|██████████| 118/118 [00:13<00:00,  8.43it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1143, Mnist Accuracy: 9910/10000, Sum Accuracy: 9847/10000, Total: (98.78%)\n",
      "\n",
      "EPOCH -  18\n",
      "Loss=0.13261687755584717 Batch_id=117 Mnist_Accuracy=98.61 Sum_Accuracy = 97.46: 100%|██████████| 118/118 [00:14<00:00,  8.42it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1144, Mnist Accuracy: 9916/10000, Sum Accuracy: 9835/10000, Total: (98.76%)\n",
      "\n",
      "EPOCH -  19\n",
      "Loss=0.149938702583313 Batch_id=117 Mnist_Accuracy=98.58 Sum_Accuracy = 97.47: 100%|██████████| 118/118 [00:13<00:00,  8.46it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1092, Mnist Accuracy: 9912/10000, Sum Accuracy: 9856/10000, Total: (98.84%)\n",
      "\n",
      "EPOCH -  20\n",
      "Loss=0.09604816138744354 Batch_id=117 Mnist_Accuracy=98.73 Sum_Accuracy = 97.56: 100%|██████████| 118/118 [00:13<00:00,  8.46it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1055, Mnist Accuracy: 9917/10000, Sum Accuracy: 9856/10000, Total: (98.87%)\n",
      "\n",
      "EPOCH -  21\n",
      "Loss=0.15737205743789673 Batch_id=117 Mnist_Accuracy=98.66 Sum_Accuracy = 97.59: 100%|██████████| 118/118 [00:13<00:00,  8.53it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1042, Mnist Accuracy: 9919/10000, Sum Accuracy: 9847/10000, Total: (98.83%)\n",
      "\n",
      "EPOCH -  22\n",
      "Loss=0.20559997856616974 Batch_id=117 Mnist_Accuracy=98.75 Sum_Accuracy = 97.55: 100%|██████████| 118/118 [00:13<00:00,  8.52it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1029, Mnist Accuracy: 9913/10000, Sum Accuracy: 9844/10000, Total: (98.78%)\n",
      "\n",
      "EPOCH -  23\n",
      "Loss=0.14880472421646118 Batch_id=117 Mnist_Accuracy=98.72 Sum_Accuracy = 97.62: 100%|██████████| 118/118 [00:13<00:00,  8.46it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1032, Mnist Accuracy: 9914/10000, Sum Accuracy: 9860/10000, Total: (98.87%)\n",
      "\n",
      "EPOCH -  24\n",
      "Loss=0.18780222535133362 Batch_id=117 Mnist_Accuracy=98.73 Sum_Accuracy = 97.64: 100%|██████████| 118/118 [00:14<00:00,  8.29it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1047, Mnist Accuracy: 9915/10000, Sum Accuracy: 9842/10000, Total: (98.78%)\n",
      "\n",
      "EPOCH -  25\n",
      "Loss=0.232062429189682 Batch_id=117 Mnist_Accuracy=98.72 Sum_Accuracy = 97.68: 100%|██████████| 118/118 [00:14<00:00,  8.41it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1007, Mnist Accuracy: 9917/10000, Sum Accuracy: 9861/10000, Total: (98.89%)\n",
      "\n",
      "EPOCH -  26\n",
      "Loss=0.12327633798122406 Batch_id=117 Mnist_Accuracy=98.75 Sum_Accuracy = 97.64: 100%|██████████| 118/118 [00:14<00:00,  8.35it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1010, Mnist Accuracy: 9917/10000, Sum Accuracy: 9847/10000, Total: (98.82%)\n",
      "\n",
      "EPOCH -  27\n",
      "Loss=0.24697978794574738 Batch_id=117 Mnist_Accuracy=98.78 Sum_Accuracy = 97.71: 100%|██████████| 118/118 [00:14<00:00,  8.14it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.1017, Mnist Accuracy: 9915/10000, Sum Accuracy: 9850/10000, Total: (98.83%)\n",
      "\n",
      "EPOCH -  28\n",
      "Loss=0.3033526539802551 Batch_id=117 Mnist_Accuracy=98.75 Sum_Accuracy = 97.72: 100%|██████████| 118/118 [00:13<00:00,  8.50it/s]\n",
      "  0%|          | 0/118 [00:00<?, ?it/s]\n",
      "Test set: Average loss: 0.0984, Mnist Accuracy: 9919/10000, Sum Accuracy: 9855/10000, Total: (98.87%)\n",
      "\n",
      "EPOCH -  29\n",
      "Loss=0.27617791295051575 Batch_id=117 Mnist_Accuracy=98.74 Sum_Accuracy = 97.66: 100%|██████████| 118/118 [00:13<00:00,  8.56it/s]\n",
      "\n",
      "Test set: Average loss: 0.0993, Mnist Accuracy: 9919/10000, Sum Accuracy: 9860/10000, Total: (98.89%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "EPOCHS = 30\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH - ', epoch)\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    scheduler.step()\n",
    "    test(model, device, test_loader)"
   ]
  }
 ]
}