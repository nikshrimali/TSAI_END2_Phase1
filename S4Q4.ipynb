{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S4Q4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35361b12-6d8b-4fa1-d2c7-8ca0f7616234"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "# import math\n",
        "\n",
        "def sigmoid(x): # sigmoid function\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return sigmoid(y) * (1-sigmoid(y))\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  # return (math.exp(x) - math.exp(-x))/(math.exp(x) + math.exp(-x)) # this gives math error, learnt it the hard way :(\n",
        "  return np.tanh(x)\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1-tanh(y)**2\n",
        "\n",
        "\n",
        "dsigmoid = np.vectorize(dsigmoid)\n",
        "dtanh = np.vectorize(dtanh)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxyD3QczLQs1",
        "outputId": "ec47c732-c19f-4b4a-e66f-d7088aa45a59"
      },
      "source": [
        "print(f'sigmoid(0) : {sigmoid(0)},\\ndsigmoid(sigmoid(0)) : {dsigmoid(sigmoid(0)):0.3f}, \\ntanh(dsigmoid(sigmoid(0))) : {tanh(dsigmoid(sigmoid(0))):0.5f}, \\ndtanh(tanh(dsigmoid(sigmoid(0)))) : {dtanh(tanh(dsigmoid(sigmoid(0)))):0.5f}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sigmoid(0) : 0.5,\n",
            "dsigmoid(sigmoid(0)) : 0.235, \n",
            "tanh(dsigmoid(sigmoid(0))) : 0.23077, \n",
            "dtanh(tanh(dsigmoid(sigmoid(0)))) : 0.94858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6e69ce-11be-4d04-f068-22c5c849ddc6"
      },
      "source": [
        "size_a = Hidden_Layer_size # write your code here\n",
        "size_b = z_size # write your code here\n",
        "size_c = X_size # write your code here\n",
        "\n",
        "print(size_a, size_b, size_c)\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 175 75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_o\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    z = np.row_stack((h_prev, x))\n",
        "\n",
        "    f = sigmoid(np.matmul(p.W_f.v ,z) + p.b_f.v) # write your code here\n",
        "    i = sigmoid(np.matmul(p.W_i.v ,z) + p.b_i.v) # write your code here\n",
        "    C_bar = tanh(np.matmul(p.W_C.v ,z) + p.b_C.v) # write your code here\n",
        "\n",
        "    C = f*(C_prev) + i*(C_bar) # write your code here\n",
        "    o = sigmoid(np.matmul(p.W_o.v ,z) + p.b_o.v) # write your code here\n",
        "    h = o*(tanh(C)) # write your code here\n",
        "    v = np.matmul(p.W_v.v ,h) + p.b_v.v # write your code here\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIbFUrOLETIC",
        "outputId": "46619417-6ac8-4e6a-c701-1ee655620d97"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5683750c-cf25-4b9c-e69b-5ce470747855"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "b40e5046-353a-4a35-f9ff-a691d63a5018"
      },
      "source": [
        "iter = 50_000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD1CAYAAACm0cXeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de0AU5f4/8PeCEGIYYaxlmVZHixOEcrDU0hAlyU55RU3Nn0VliaZJCZnH7HQKxUveKFPTSLQ8UqcvqYl5SzPEyxYBXvAuKsIuF0FguSzP749lZ3dYcLks6OT79Y8+w8zsZ2Zn3zv7zLOzKiGEABERKZLDjS6AiIgajyFORKRgDHEiIgVjiBMRKRhDnIhIwVq15IPp9XqkpaXB09MTjo6OLfnQRESKZDAYoNVq4e3tDRcXF6u/t2iIp6WlYezYsS35kEREfwnr16+Hv7+/1fQWDXFPT0+pmLvvvrslH5qISJGuXLmCsWPHSvlZU4uGuKkL5e6778Z9993Xkg9NRKRodXVB88ImEZGCMcSJiBSMIU5EpGAMcSIiBWOIExEpGEOciEjBFBPir3x1CM8t3XejyyAiuqm06Djxpth1POdGl0BEdNNRzJk4ERFZY4gTESkYQ5yISMEY4kRECsYQJyJSsHqNTtHr9fjnP/+JSZMm4eDBg0hPT4e7uzsAIDQ0FAEBAUhISEBsbCwcHBwwcuRIhISENGvhRERUzxD//PPPcccdd0jt6dOno1+/flK7pKQEMTExiI+Ph5OTE0aMGIGgoCAp6ImIqHnY7E45ffo0Tp06hYCAgDrnSUlJgY+PD9zc3ODi4gI/Pz9oNBp71klERLWwGeLz5s1DZGSkbFpcXBzGjx+Pt99+G3l5edDpdPDw8JD+7uHhAa1Wa/9qiYhI5rrdKT/88AO6deuGjh07StMGDx4Md3d3eHl5YeXKlVi+fDm6d+8uW04I0TzVEhGRzHXPxPfs2YOdO3di5MiR2LRpEz777DMIIeDl5QUACAwMREZGBtRqNXQ6nbRcTk4O1Gp181ZORETXPxNfvHix9P9ly5bh3nvvxTfffIOOHTuiY8eOSE5ORpcuXeDr64tZs2ahsLAQjo6O0Gg0mDlzZrMXT0R0q2vwDbDGjh2LadOmoXXr1nB1dUVUVBRcXFwQHh6O0NBQqFQqhIWFwc3NrTnqJSIiC/UO8SlTpkj//+6776z+HhwcjODgYPtURURE9cJvbBIRKRhDnIhIwRjiREQKxhAnIlIwhjgRkYIxxImIFIwhTkSkYAxxIiIFY4gTESkYQ5yISMEY4kRECsYQJyJSMIY4EZGCMcSJiBSMIU5EpGAMcSIiBWOIExEpGEOciEjB6hXier0eAwYMwPfff4+srCy89NJLGDNmDKZOnYry8nIAQEJCAoYPH46QkBBs2rSpWYsmIiKjeoX4559/jjvuuAMAsHTpUowZMwYbNmxAp06dEB8fj5KSEsTExOCrr77CunXrEBsbi4KCgmYtnIiI6hHip0+fxqlTpxAQEAAASE5ORv/+/QEA/fr1Q1JSElJSUuDj4wM3Nze4uLjAz88PGo2mWQsnIqJ6hPi8efMQGRkptUtLS+Hs7AwAaNeuHbRaLXQ6HTw8PKR5PDw8oNVqm6FcIiKydN0Q/+GHH9CtWzd07Nix1r8LIRo0nYiI7KvV9f64Z88eZGZmYs+ePbhy5QqcnZ3h6uoKvV4PFxcXZGdnQ61WQ61WQ6fTScvl5OSgW7duzV48EdGt7rohvnjxYun/y5Ytw7333ovff/8diYmJGDx4MLZv344+ffrA19cXs2bNQmFhIRwdHaHRaDBz5sxmL56I6FZ33RCvzZQpUxAREYGNGzeiQ4cOGDJkCJycnBAeHo7Q0FCoVCqEhYXBzc2tOeolIiIL9Q7xKVOmSP9fu3at1d+Dg4MRHBxsn6qIiKhe+I1NIiIFY4gTESkYQ5yISMEY4kRECsYQJyJSMIY4EZGCMcSJiBSMIU5EpGAMcSIiBWOIExEpGEOciEjBGOJERArGECciUjCGOBGRgjHEiYgUjCFORKRgDHEiIgVjiBMRKZjNn2crLS1FZGQkcnNzUVZWhkmTJiExMRHp6elwd3cHAISGhiIgIAAJCQmIjY2Fg4MDRo4ciZCQkGbfACKiW5nNEN+9eze8vb3x2muv4dKlS3jllVfQvXt3TJ8+Hf369ZPmKykpQUxMDOLj4+Hk5IQRI0YgKChICnoiIrI/myE+aNAg6f9ZWVlo3759rfOlpKTAx8dH+pV7Pz8/aDQaBAYG2qlUIiKqqd594qNHj8Y777yDmTNnAgDi4uIwfvx4vP3228jLy4NOp4OHh4c0v4eHB7Rarf0rJiIiic0zcZNvv/0Wx44dw7vvvouZM2fC3d0dXl5eWLlyJZYvX47u3bvL5hdC2L1YIiKSs3kmnpaWhqysLACAl5cXDAYDunbtCi8vLwBAYGAgMjIyoFarodPppOVycnKgVqubqWwiIgLqEeKHDx/GmjVrAAA6nQ4lJSWYPXs2MjMzAQDJycno0qULfH19kZqaisLCQhQXF0Oj0cDf3795qyciusXZ7E4ZPXo03n//fYwZMwZ6vR6zZ8+Gq6srpk2bhtatW8PV1RVRUVFwcXFBeHg4QkNDoVKpEBYWJl3kJCKi5mEzxF1cXLBw4UKr6d99953VtODgYAQHB9unMiIisonf2CQiUjCGOBGRgjHEiYgUjCFORKRgDHEiIgVjiBMRKRhDnIhIwRjiREQKxhAnIlIwhjgRkYIxxImIFIwhTkSkYAxxIiIFY4gTESkYQ5yISMEY4kRECsYQJyJSMIY4EZGCMcSJiBTM5m9slpaWIjIyErm5uSgrK8OkSZPwyCOPYMaMGTAYDPD09MT8+fPh7OyMhIQExMbGwsHBASNHjkRISEhLbAMR0S3LZojv3r0b3t7eeO2113Dp0iW88sor8PPzw5gxY/Dss89i0aJFiI+Px5AhQxATE4P4+Hg4OTlhxIgRCAoKgru7e0tsBxHRLclmd8qgQYPw2muvAQCysrLQvn17JCcno3///gCAfv36ISkpCSkpKfDx8YGbmxtcXFzg5+cHjUbTvNUTEd3ibJ6Jm4wePRpXrlzBihUr8PLLL8PZ2RkA0K5dO2i1Wuh0Onh4eEjze3h4QKvV2r9iIiKS1DvEv/32Wxw7dgzvvvsuhBDSdMv/W6prOhER2Y/N7pS0tDRkZWUBALy8vGAwGNCmTRvo9XoAQHZ2NtRqNdRqNXQ6nbRcTk4O1Gp1M5VNRERAPUL88OHDWLNmDQBAp9OhpKQEvXv3RmJiIgBg+/bt6NOnD3x9fZGamorCwkIUFxdDo9HA39+/easnIrrF2exOGT16NN5//32MGTMGer0es2fPhre3NyIiIrBx40Z06NABQ4YMgZOTE8LDwxEaGgqVSoWwsDC4ubm1xDYQEd2ybIa4i4sLFi5caDV97dq1VtOCg4MRHBxsn8qIiMgmfmOTiEjBGOJERArGECciUjCGOBGRgjHEiYgUjCFORKRgDHEiIgVjiBMRKRhDnIhIwRjiREQKxhAnIlIwhjgRkYIxxImIFIwhTkSkYAxxIiIFY4gTESkYQ5yISMEY4kRECmbz59kAIDo6GkeOHEFlZSUmTpyIXbt2IT09He7u7gCA0NBQBAQEICEhAbGxsXBwcMDIkSMREhLSrMUTEd3qbIb4gQMHcPLkSWzcuBH5+fkYOnQoevbsienTp6Nfv37SfCUlJYiJiUF8fDycnJwwYsQIBAUFSUFPRET2ZzPEe/TogcceewwA0LZtW5SWlsJgMFjNl5KSAh8fH+kX7v38/KDRaBAYGGjnkomIyMRmn7ijoyNcXV0BAPHx8ejbty8cHR0RFxeH8ePH4+2330ZeXh50Oh08PDyk5Tw8PKDVapuvciIiql+fOADs2LED8fHxWLNmDdLS0uDu7g4vLy+sXLkSy5cvR/fu3WXzCyHsXiwREcnVa3TKvn37sGLFCqxatQpubm7o1asXvLy8AACBgYHIyMiAWq2GTqeTlsnJyYFarW6eqomICEA9QryoqAjR0dH44osvpIuUU6ZMQWZmJgAgOTkZXbp0ga+vL1JTU1FYWIji4mJoNBr4+/s3b/VERLc4m90pW7duRX5+PqZNmyZNGzZsGKZNm4bWrVvD1dUVUVFRcHFxQXh4OEJDQ6FSqRAWFiZd5CQiouZhM8RHjRqFUaNGWU0fOnSo1bTg4GAEBwfbp7I6CCGgUqma9TGIiJRCcd/YvHxVf6NLICK6aSguxDnqhYjITIEhfqMrICK6eSguxImIyIwhTkSkYAxxIiIFY4gTESmY4kKcFzaJiMwUF+JERGTGECciUjCGOBGRgjHEiYgUjCFORKRgigtxAQ5PISIyUVyIExGRmeJCnOPEiYjMFBfiRERkxhAnIlIwhjgRkYLZ/I1NAIiOjsaRI0dQWVmJiRMnwsfHBzNmzIDBYICnpyfmz58PZ2dnJCQkIDY2Fg4ODhg5ciRCQkKau34ioluazRA/cOAATp48iY0bNyI/Px9Dhw5Fr169MGbMGDz77LNYtGgR4uPjMWTIEMTExCA+Ph5OTk4YMWIEgoKC4O7u3hLbQUR0S7LZndKjRw8sWbIEANC2bVuUlpYiOTkZ/fv3BwD069cPSUlJSElJgY+PD9zc3ODi4gI/Pz9oNBq7F8zBKUREZjZD3NHREa6urgCA+Ph49O3bF6WlpXB2dgYAtGvXDlqtFjqdDh4eHtJyHh4e0Gq1zVQ2EREBDbiwuWPHDsTHx2P27Nmy6XX9+nxz/So9f+2eiMisXiG+b98+rFixAqtWrYKbmxtcXV2h1+sBANnZ2VCr1VCr1dDpdNIyOTk5UKvVzVM1EREBqEeIFxUVITo6Gl988YV0kbJ3795ITEwEAGzfvh19+vSBr68vUlNTUVhYiOLiYmg0Gvj7+zdv9UREtzibo1O2bt2K/Px8TJs2TZo2d+5czJo1Cxs3bkSHDh0wZMgQODk5ITw8HKGhoVCpVAgLC4Obm5vdCzZ1phw+l4f7PVyhbuti98cgIlIKmyE+atQojBo1ymr62rVrraYFBwcjODjYPpXZMGJFEjzaOEPzr6AWeTwiopuR4r6xqbL4f15x+Q2rg4joZqC4EOfYFCIiM8WFOBERmSkuxE9mF8na53OLb1AljVdpqMKpnGs3ugwi+gtQXIjP+iFN1k4+m3eDKmm8qJ+OY8CiX5CZV3KjSyEihVNciFt9YVOBneSHzhnfeHhhloiaSnkhbtVWXorzzgFEZC/KC/EGJOCqvWcQd+B8M1bTNCqV7XmIiK5HcSGur6iSta+X6R9vPWbVh25v5ZVV+PePR3G1pEKatnzXSSSdzq1zGSV+eiCim5PiQry0wnCjS5D5vz8uYc3+s5i77bg0bcH2DLy46kCdy5jeeFQWX10qLTfwDo1E1GCKC/GmyCnS49eTuuvOszdDi5xCfb3XWVUdvJWGqjrnWbv/LGb/n/UnAlN3ysX8EnjN3oa45AuyWov0FVbLmGQX6vHuphSUVZrf1H5KzZJ9IijSV6C0/OZ606PaVVXJ38ArDVWyaZWGKpRXmo8xIQSKyyplyxSUlMtOBK6WVkBvcdKjrzCgoKRcto6L+fIRUpcKSmXHsu5ameyYKimvxKWCUtk6jl8plK3jrK5Y9rg5RXrkFOll66g5VPiPzAJZ7adyrqHQ4vjPKdLLRnPpKww4eln+uJoL+TBUWa6jCLnXyqR2fnG5bB1CCGQ34LV+s1J8iDfk3DVkRRLGfZkstU/lFKFz5BacyjEfUOPXHMSwz3+r9zpNZ9PXq+PDH4/i6yRz33zNE+5zOuOBtS0tS5r2+Mc70X/hL1L7UkEpjpzPl9of/F86Nh25iF3HcqS/v7leg8nfmH9NyWfOdvSau1Nq/2fzUXSO3CK1j2UVonPkFlzINT5+VZXAwE/3Ysuf5jqith5D1NZjUnvnsWyMXpkkveByr5Xh+WW/ysJg8gaNbFtW7zsjW8fhc3kYvTIJFdVhUaSvwKAl+5Bh8cIOW6/B+mTzPlu59zTC1pu37cj5PDzxyQ7pja6kvBL+//lZ9ib90pfJ+HjLUam9fNdJBC7cI7V/v5CPzpFbcLk6lMorq9A5cgs2HjK/mQ77bD9e+eqQ1F6y46RsH6ZevIrOkVuQevGqNK1z5BZEW3wye27pPvSKMj8Py3Ya12EKuhNXivDgzK34+Wi2NM/f3v8Jb64/IrX/uexXdJ31k9T+/JfTePSDRCkcL+SWoNu/f8ba/eekeXw/3I5BS/ZZbMtv6Pbvn6X2mv3n8NS83VIY5l4rw5Nzd+E/W8zPlf9/dqDbR9ul9rjVyXhy7i6pvenIRQQv3ofdJ4zHYYWhCv0W7JE9V49/vBOPf2ze/jfiNAj6dK/0/G9Pv4IhMfux8VCmNM+ARb9g1BcHZOvoE71bas/8PhWDlu6Ttv/I+XwM++w3LN91ymIde9F/kfk11Cd6t2wdK345gyc+2YmzOuN3TYr0FXjwvS3Yddz8PLy89iDm/mR+LuMOnMdLFhmy+0ROdYYYv/dRWb3929OvSPN8svUYluw4ieai+BBviPO58rOOH1OMQZOQkiWbfjHffKaRmVeCM9rrfDGnGS9O5hSZzyKenLsLw6/z5mIKBMvaAaDA4ixq9a9nZX/bdPgiAGD7UeMBV26owonsIkz/7x/SPF/sPYMv9p6R2m/GaXDgTB7Kq1+A//v9ElIvXcWaX89J82z+MwtvxJlfxP/Zcky2jnc2peDAmTyp1l9P6nA0qxCLtmdI82xJzcL7/zN/evlk63FsSTU/Twu3ZyC7sAx/Vofnyexr0F0rR3Si+QW376QOq/aZt3nB9gyc0Zq/HLa++pOPKfivlhr3VfS2E9I8mgsF2HU8R2p/usNcIwD8fMz4gt9xLFs2/bM9p6X/p18uRNZV8xnf2t/OAQCuVZ9J/5FpfHO2fOEDQGK6eZ3Hr8jPXLdW74sr1es9n2fcrp3H5XWc0Zm392iW/Mz14FnjdRvTF+ZM27/nRI5sPsuTDs2FAtnfjlWv83R1iJnOhPdd5xNv0mnj30yfYs9VP37NL8Adq1GvpSMXjPusuMx43GddNR5LJ7Lly1ge/9dqfHLZd9L4y2OmN/HT2mJUCcgCd/cJLVb8Yn4uZ/2QJtu2rdUnPJrqE6y8knKc1RVjpsWxu3LvGavjxp4UH+Kf/pyBxz/eAcB4NmLZvWBLfUaH9InejUCLM2J9hUF2xmhij+7shqxjW/UL3rRIY95Lal5grc/j86Js09njfV9lh7XU/BSpUtn+VGmrDtNrqj7HSV3LNkTNRRqyX/4ql6AUH+I5RWXIKSrDtbJK9J2/GxHxfzZ8JQ14Nqf/9w888+leqb/OdMg0JdzsMdRwzo/GbgNTN0fNPtbrP37TX0yNUfNCbmP2Yc2n7q/ywmwJNZ/nxjztUmjXcrFeKWpW3JhDyPrYbbkDUfEhbmK6gHe9j3E11ac/u6aDZ40fm0zdFzUDsD7s+fSaXjx7M+Q/Sj3PolsBgOyCj0mRvtJqWkuwx5uGVQDZ4yzODutoDHueVTdGU94I63rU662jpT+11ldT3sTM62j5NzGbPwqhFOaPcdamfPM7frLoTxVCQKVSWZ1FtLSyyiqsSzqHB+66vd51HL9SaHOEDQD88PslWXtb2hWreeKPXJS1v/z1jKxd220BKgzGIk0Hq/nNzGZJVqzOXRrxPFh1CTXmbN5qHY2poxHL1AxPe6yjAStxkLpPqp/TBnSFmNRc5nqvw7qWbYqmrKPmdt7oPGgsRYb4vG3HraZpqy8C1jbW+seUy7K2EMYnzKERB615JTba12G6YLNw+wn8djoX/p3uBACroVq1eW7pr7Kz6mtlFbIupJJyAy7kllh9KarcYPtawYLt8osv72xKkbVrDgurbRnL0SAArC4KCyGk0QAmB87Ib2KmsxgWZlqmJssLVsZ5rGaxqSndCTVPBJryuI05ebPHJxHT45oOJynUG3ImXr2MaR1S92I9VmKa5YafmatM/8jf1Brz+DfijaBeIZ6RkYFJkyZhwoQJGDduHCIjI5Geni79cHJoaCgCAgKQkJCA2NhYODg4YOTIkQgJCWmWoj+3uPJvstJi9IO2qAxuLrY3reYBWJ+LojVfLL9Ud2OcbMStZU2jTw5XX9nOL6l7XLhJzW6R+YknoLtmPmPOKSpD3/m7ZfO8GntYNnoi7dJVrLMY8lhcVomY3eahWfqKKhw4kysbh5tTpIfmgnmIY5UQNcbcGodoWY4GAYCFP8tDvuboGQD4qnq0hmnLhn62X/b37zTyTxVVVQLpNcYID47ZL9UBGIc1WrIc22zy38PyTyI//HG5eh3GlVyoMZrJ8jqD6URA2q/Vy9R809LX8uU00/NlCovLNWorKbfdzVVS3X1oqqiqEalRV+A2pjvFHGLy11Rt6vpTQ7om6wzaFu7NsLo4XP1vS57M20y6kpISfPTRR+jVq5ds+vTp09GvXz/ZfDExMYiPj4eTkxNGjBiBoKAgKeibm2nn6Suq0OPjHej1YLs65zXtYNPZe3llFWb+LxUBXT1l89V25mm5juxCPRKruylSL12tc96G6By5BbP/+fd6z28Z4HWpOfxt7OpkaTgZACzZedLqzWH0Svk3Ti3H+QLAgsQTsiGLGw6ex5r98gC3HE8NAO99n4pvDprHYB88mycbC//z0Ww8NW+XLOg/2nwUX1o8zp4TOUi0GIqXe61c9okh/XIhluw4KRvS9fPRbHyddE5qn88tll1D0BaVYcUvp6XxwPklFfgpNQvvWnzCSb98VdYlVVBageQzuUi7ZHwzycwvxU+pWXjTYnz0H5kF+MzizTHraqk0P2Dsmko+k4vF1UPaTlwpwh+ZBZi+0TzEMzOvBNstxo8X6iuQU6iXhuMJIXAyuwgvfXkQgPELL5l5JYj9zby9BSXlOGExRLG8sgqF+gpsrh4eV1ZZBW1RmfQt40sFpSjUV+CAxa0jyioNsi/9VFUJlFVWSUNHC0rLoa8wyJ7fSkMVLheYh1YKIVAlrE9Eoqr3u+mLN6a7fJrUHBpo3C/GY8QUoqbn1zRcsuYbY20X+qVPgNV/Oln9fZErV425UNsbcE2mYa+mL0iZXlemrsiGDDBoLJWw8bmnsrISlZWVWLVqFe68807pTHzgwIGyEE9KSsJ3332HBQsWAABmz56NgIAABAYGSvNcvHgR/fv3x86dO3Hfffc1qNCagdAU7zzT1aoboKbX+z4oO7s/N/c5WR1LRnfD1G//kC0THtQVI3t0xBOfGANv7cs90K6NM15YbjxL3DejHzYduYilO40vWk+326Q3Ekt3ujpJZ+UTendGm9scEbPb+tOH0rVxdkRxE79Retftt1l1vzSU222tUFRLUFzPI3e7WY3dbqj+j6ix83iO7RktODmqpOsSADC4Wwf83x+Xr7OENb/73WXjvft0uatBAwIAYOwT90vj7AHggbvaWHWT1XTX7c6yk46Zgx7BJ1vNXaOtnRxt3lYj4GFP7DlhfgP+8IVH8UFC+nWXqbneSQEPycbxvzvwYcxPPCFbpuZ+Hvhoexw4kyeF9NxhPvh46zFpcMBzPvcgMf0KKi1Cu4v6duiulUmvZVOGNJSt3LQZ4ibLli2ThbhWq0VFRQXatWuHf/3rX9i/fz9SU1Mxc+ZMAMDixYtxzz33YNSoUfUu5nrsGeKNUTPEJ/Z9UPYFFpNO7VytvlRERDcvV2dHqXuqOTVXiDfqwubgwYPh7u4OLy8vrFy5EsuXL0f37t1l8/wVb+ZUn49GDHAiZWmJAG9OjRon3qtXL3h5eQEAAgMDkZGRAbVaDZ3O/JEsJycHarXaPlXeBHafyMFT83bZnpGIqAU1KsSnTJmCzEzjzWqSk5PRpUsX+Pr6IjU1FYWFhSguLoZGo4G/v79di72RXl57CJct7n9RW1cKEVFdLO9CaU82u1PS0tIwb948XLp0Ca1atUJiYiLGjRuHadOmoXXr1nB1dUVUVBRcXFwQHh6O0NBQqFQqhIWFwc3NrVmKJiJSmmeX7MXO8AC7r9dmiHt7e2PdunVW0wcOHGg1LTg4GMHBwfapjIjoL+S09vqjdxrrL3PvFCKiWxFDnIhIwRjiREQKxhAnIlIwhjgRkYIxxImIFIwhTkSkYAxxIiIFY4gTESkYQ5yISMEUE+KPd/a40SUQEd10FBPiGyf2vNElEBHddBQT4iqVCu8OfPhGl0FEdFNRTIgDQFi/vyHtQ+u7JxIR3aoUFeIAcPtt5rvnvtW/C6YN6GI1zzN/b9+SJRER3TCKC3FL04O6YtqArlgzwfwLQufmPoeV483tng96XPcHSr97szfuaO1kNb1929saXM9j990h/f/dgQ/jzYCHGryOZ73vlrWf87lH1v7g+b9btQd4tZfNnzitr9QOfvRuHJ41QLb+ja+bry88+bd2mPP83/H/enWSpkUEP4KD7/eX2jOCH8au8Kel9tsDuuLrVx6X2kF/b49PhvrIursWhvjKHnfecB9sfauP1P734EexZoI/3FxaSetYNNIXc4f5SPN89XIPJL0XKLVXj/fHD2FPSu1PR/li5Uv/wIOebQAAj3Zoi5gxfrLjYf2rT2DfjH5Se+2EHoh/o5fUXjK6Gz4f64en/nYXAMCjjTNWjffHlreekub55rWe2Gmx/bGvPI5vLfbh4lHdsHxMd4zu0VFW+6H3zdv/7es9sf1t8/Oy4dUnsP7VJ6T2zEGPIGaMH8KDusrmOTjT/Dz8d2Iv2T6MC30CX7/yuLQPJ/TujBXj/oFFI32leb57s7dsH/5vUm/8ONm8bRteewJrJ/TAox3aAgD6dvXE2gk9ZNv3v0m9Zfsw/o1e+N+k3lJ75Uv/wOrx/hjkYzx227q0QlzoE1bL7H4nQLZtls9D1DAfrBrvj9f7PihN2/h6TxyxOIZ+CHsSP1vsw/g3emHDa+Z9GBH8CFa+9A98NPhR2fZbHstb3nrK6rldM8Ef93u4AgCee+weLBndDassMmTDq09gj0Xtm97ohW9eM++ftS/3wPIx3aVj6OH2blg+pjs2T5E/juXzb1eiBWVmZoquXbuKzMzMJq3n15NasXRHhiRbzaMAAA5LSURBVGzaqZwiUVpeKbU7RWwWnSI2i4wrhbJ2QXG5OJldKN6MOyw6RWyW5q+qqhILEo+LuAPnrNZhMFSJ0K8OSe2f068Ig6FKLN2RITpFbBYfbzkq3v72d1FQXC6yr5YKXZFeto7nl+0T1/QVIvdambSOQ2dzxS8nckRhabn4KTVLmr+4rEIM+2y/OJZ1VZo2eYNGrNp7WpRXGoQQQgQt2iOrfdXe06JTxGZpGdPjRG87Jqujb/QuqT1lg0a2jj0nckSniM0i9WKBEEKIikqD6BSxWczfdlyaJ2D+btF/4R6pvWj7CWn/CCHE0ctXRaeIzeLwuVzZ40ZtNdfx8tqDYoDFOr5JPi86RWwWJWXG5+5SfonoFLFZ/HpSK83j/5+fxYcJ6VJ75vd/isAFu6X2jqNXRKeIzSK/uEwIIURBSbnoFLFZJKaZ9+vzy/aJmd//Kav9qXk7pfaR83miU8RmkVVQKoQQoqzCILz+9ZP44feL0jyhXx0U4f/9Q2p/nXRO9I4yr+NUTpF48L0t4qz2mjTtqXk7xbcHz0vtyO/+FG99o5HaW/68LHpH7RQV1c9t9tVS4fthojieVSjNM/yz/SL2t7NSe2HicTFp/RGpvf+UVvSN3iUd/4Wl5aLPvF3ijwv50jyT4o6I1fvOSO21v54RE78+LLXTLhWIfvN3i6ul5UIIIfQVlSJ48V7x2ymdrPZlO82vu++OZIrxXyZL7fO6YhG0aI/QVh//BkOVGP7ZfrHj6BVpnk+2HBXzfjIfDz+nXxFjViWJqirjMZRdWCoGfvqLuJhfIs3z8tqD4seUS1J72c4MMSchTWr/dkonhn22X3p9FJSUi2cX7xUns837cOo3GrHx0AXZ9s/YlCK1D5/LFU/N2ymu6SuEEMbXYd/oXSL5jPlYnrxBI9v+b5LPi1djD0ntE1cKRZ95u0TeNeNxWFFpEIOX/yr2ZuSIprCVmyohWu5n6S9evIj+/ftj586duO+++5r1sc7nFuOXDC3G9+oMANh3UgsXJ0f0qB6qKISAoUqglWPdH0YWJJ7AM4+2x2P3uTe6jitX9WjbuhVcnY1nS50jtwDAdT8d2FJaboC+woA72zgDMG7LxfxSdKw+mwCAgpJytHVxgoODCgBQVmmAg0oFp+rtraoSMAghtU3rUalUja6LiOzPVm7WqzslIyMDAwYMQFxcHAAgKysLL730EsaMGYOpU6eivLwcAJCQkIDhw4cjJCQEmzZtsuNmNFyndm2kAAeAPl08pQAHjKNdrhfgAPDOwIebFOAAcPcdLlKAA8CDd7Vp0voAoLWzoxTggHFbLAMcANxdnaUAB4DbWjnKAtvBQSVrm9ZDRMpiM8RLSkrw0UcfoVcvc//V0qVLMWbMGGzYsAGdOnVCfHw8SkpKEBMTg6+++grr1q1DbGwsCgoKmrV4Jdo2rS+Of8TfISUi+7AZ4s7Ozli1ahXUarU0LTk5Gf37Gy8W9OvXD0lJSUhJSYGPjw/c3Nzg4uICPz8/aDSa5qtcoZxbOcDFyfFGl0FEfxE2f+2+VatWaNVKPltpaSmcnY0f59u1awetVgudTgcPD3N3hYeHB7RarZ3LJSIiS00eYljXddEWvF5KRHTLalSIu7q6Qq/XAwCys7OhVquhVquh0+mkeXJycmRdMEREZH+NCvHevXsjMTERALB9+3b06dMHvr6+SE1NRWFhIYqLi6HRaODv729jTURE1BQ2+8TT0tIwb948XLp0Ca1atUJiYiIWLFiAyMhIbNy4ER06dMCQIUPg5OSE8PBwhIaGQqVSISwsDG5ubi2xDUREtyybIe7t7Y1169ZZTV+7dq3VtODgYAQHc/gcEVFLsRni9mQwGAAAV65cacmHJSJSLFNemvKzphYNcdOQw7Fjx7bkwxIRKZ5Wq0WnTp2sprfovVP0ej3S0tLg6ekJR0d+4YWIyBaDwQCtVgtvb2+4uLhY/b1FQ5yIiOxL0fcTJyK61bVon3hjffLJJ0hJSYFKpcLMmTPx2GOP3ZA6oqOjceTIEVRWVmLixInYtWsX0tPT4e5uvNNhaGgoAgICkJCQgNjYWDg4OGDkyJEICQlBRUUFIiMjcfnyZTg6OiIqKgodO3a08YgNl5ycjKlTp6JLF+MvHnXt2hWvvvoqZsyYAYPBAE9PT8yfPx/Ozs43tM5NmzYhISFBaqelpcHb2xslJSVwdTXekTEiIgLe3t5YvXo1tm3bBpVKhcmTJ+Ppp59GUVERwsPDUVRUBFdXVyxcuFB6HuwhIyMDkyZNwoQJEzBu3DhkZWU1eR8eP34cc+bMAQA8/PDD+PDDD5ulzvfeew+VlZVo1aoV5s+fD09PTzz66KPw8/OTlvvqq69QVVXVInXWrDEyMrLJr5uW2JdvvfUW8vPzAQAFBQXo1q0bJk6ciOeffx7e3t4AgDvvvBNLly6t83j87bffsGjRIjg6OqJv374ICwtrcp1WmnS38haQnJwsXn/9dSGEEKdOnRIjR468IXUkJSWJV199VQghRF5ennj66adFRESE2LVrl2y+4uJi8cwzz4jCwkJRWloqnnvuOZGfny++//57MWfOHCGEEPv27RNTp05tljoPHDggpkyZIpsWGRkptm7dKoQQYuHChWL9+vU3vE5LycnJYs6cOWLcuHHixIkTsr9duHBBDB06VJSVlYnc3FwxcOBAUVlZKZYtWyZWrVolhBDi22+/FdHR0Xarp7i4WIwbN07MmjVLrFu3Tghhn304btw4kZJi/CGC6dOniz179tTy6E2rc8aMGWLLli1CCCHi4uLEvHnzhBBCPP7441bLt0SdtdVoj9dNS+xLS5GRkSIlJUVkZmaKoUOHWv29ruPx2WefFZcvXxYGg0G8+OKL4uTJk02qszY3fXdKUlISBgww/kTTQw89hKtXr+LatWstXkePHj2wZMkSAEDbtm1RWlpa65Cfuu7mmJSUhKCgIADGb7y25B0eG3LXyRtRZ0xMDCZNmlRn7X369IGzszM8PDxw77334tSpU7I6TdtkL029c2dt+7C8vByXLl2SPkXao+ba6vzggw8wcKDxx8TvvPPO694OuiXqrK3G2tyM+9LkzJkzKCoqum4PQG3HY2ZmJu644w7cc889cHBwwNNPP23X49Tkpg9xnU6HO++8U2rfqLsjOjo6Sh/z4+Pj0bdvXzg6OiIuLg7jx4/H22+/jby8vDrv5mg53cHBASqVSvoxDXs7deoU3njjDbz44ovYv39/g+462ZJ1AsCff/6Je+65B56engCM96ofO3YsZs+eDb1eX68627Vrh5ycHLvV1KpVK6tRAE3dhzqdDm3btpXmNa3D3nW6urrC0dERBoMBGzZswPPPPw8AKC8vR3h4OEaPHi19Ua8l6qytRgBNet201L40+frrrzFu3DiprdPp8NZbb2H06NFSl2Btx6NWq22RO7sqok/ckrjBg2l27NiB+Ph4rFmzBmlpaXB3d4eXlxdWrlyJ5cuXo3v37rL566q3ubajc+fOmDx5Mp599llkZmZi/Pjxsk8MDa2nufd3fHw8hg4dCgAYP348Hn74Ydx///344IMPsH79+nrV09LHhD32YXPWbDAYMGPGDPTs2VP6MZcZM2bghRdegEqlwrhx42q9r1FL1Tl48GC7vm6ac1+Wl5fjyJEjUv+7u7s7pk6dihdeeAFFRUUICQlBz549Zcu09PF405+J13Z3RNNZW0vbt28fVqxYgVWrVsHNzQ29evWCl5cXACAwMBAZGRl13s1RrVZL78IVFRUQQkhndvbUvn17DBo0CCqVCvfffz/uuusuXL16td53nWypOk2Sk5OlF3BQUBDuv/9+AHXvT8v6TXWapjWnhty5s7Z96OnpKevaaM6a33vvPXTq1AmTJ0+Wpr344oto06YNXF1d0bNnT2nf3og6m/q6acl9eejQIVk3yu23347hw4fDyckJHh4e8Pb2xpkzZ2o9Hus6du3tpg/xJ598UrpjYnp6OtRqNW6//fYWr6OoqAjR0dH44osvpKvqU6ZMQWZmJgBjGHXp0qXOuzk++eST2LZtGwBg9+7deOKJJ5qlzoSEBHz55ZcAjN/wys3NxbBhw+p918mWqhMwHtRt2rSBs7MzhBCYMGECCgsLAZj3Z8+ePbFnzx6Ul5cjOzsbOTk5+Nvf/iar07RNzakhd+6sbR86OTnhwQcfxOHDh5u15oSEBDg5OeGtt96Spp05cwbh4eEQQqCyshIajQZdunS5YXU29XXTUvsSAFJTU/HII49I7QMHDiAqKgqA8acrjx8/jgceeKDW4/G+++7DtWvXcPHiRVRWVmL37t148skn7V6jIr7ss2DBAhw+fBgqlQoffPCBbKe2lI0bN2LZsmV44IEHpGnDhg1DXFwcWrduDVdXV0RFRaFdu3bYtm0bvvzyS+mj6wsvvACDwYBZs2bh3LlzcHZ2xty5c3HPPffYvc5r167hnXfeQWFhISoqKjB58mR4eXkhIiICZWVl6NChA6KiouDk5HRD6wSMwwoXL16M1atXAwC2bt2K1atXo3Xr1mjfvj0+/vhjtG7dGuvWrcOPP/4IlUqFadOmoVevXiguLsa7776LgoICtG3bFvPnz7fbXTNr3rmzffv20p07m7IPT506hdmzZ6Oqqgq+vr5477337F5nbm4ubrvtNulE56GHHsKcOXMwf/58HDhwAA4ODggMDMSbb77ZInXWVuO4ceOwcuXKJr1uWmJfLlu2DMuWLcM//vEPDBo0CABQWVmJWbNm4ezZszAYDHjxxRcxfPjwOo/HQ4cOYcGCBQCAZ555BqGhoU2qszaKCHEiIqrdTd+dQkREdWOIExEpGEOciEjBGOJERArGECciUjCGOBGRgjHEiYgUjCFORKRg/x+AlWU5hsfeMwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " pot tnrnwasa   hoOye cUkvnn bei,w theOBt ednt t xent( fn  diraogatn \n",
            "rs  oe censrta snhneb t  e anetroi1nnBu0teo.trfneo i i:abehane re or hCtriutgei Satthtyruh hoewrghtespt i sboe i ssidai rc  htuatih \n",
            "----\n",
            "iter 18200, loss 125.739841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}