{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Reading and data and display sample\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = os.path.join(os.getcwd(),'data/nikhil_onlytextpytorch.json')\n",
    "print(path)\n",
    "\n",
    "train = pd.read_json(path, orient='index')\n",
    "display(train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/Users/nik/Documents/Codes/random_stuff/TSAI_END2_Phase1/data/nikhil_onlytextpytorch.json\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "                                                                     answer  \\\n",
       "What values are specified to replaceNaN, positi...  bynan,posinf, andneginf   \n",
       "By default,NaN is replaced with what value?                            zero   \n",
       "What values are used to replace negative infini...  bynan,posinf, andneginf   \n",
       "What is the default value for negative infinity?     the least finite value   \n",
       "What is the value to replace positive infinity ...                   posinf   \n",
       "...                                                                     ...   \n",
       "What is the tensor of shape where*is zero or mo...                A(Tensor)   \n",
       "What is the tolerance value to determine when i...                    rcond   \n",
       "What is the default value of atorch.Tensor?                           1e-15   \n",
       "What computes the inverse of a square matrix?            torch.linalg.inv()   \n",
       "What is the tensor of shape(*, m, n)where*is ze...                A(Tensor)   \n",
       "\n",
       "                                                                                             question  \\\n",
       "What values are specified to replaceNaN, positi...  What values are specified to replaceNaN, posit...   \n",
       "By default,NaN is replaced with what value?               By default,NaN is replaced with what value?   \n",
       "What values are used to replace negative infini...  What values are used to replace negative infin...   \n",
       "What is the default value for negative infinity?     What is the default value for negative infinity?   \n",
       "What is the value to replace positive infinity ...  What is the value to replace positive infinity...   \n",
       "...                                                                                               ...   \n",
       "What is the tensor of shape where*is zero or mo...  What is the tensor of shape where*is zero or m...   \n",
       "What is the tolerance value to determine when i...  What is the tolerance value to determine when ...   \n",
       "What is the default value of atorch.Tensor?               What is the default value of atorch.Tensor?   \n",
       "What computes the inverse of a square matrix?           What computes the inverse of a square matrix?   \n",
       "What is the tensor of shape(*, m, n)where*is ze...  What is the tensor of shape(*, m, n)where*is z...   \n",
       "\n",
       "                                                                                              context  \\\n",
       "What values are specified to replaceNaN, positi...  ReplacesNaN, positive infinity, and negative i...   \n",
       "By default,NaN is replaced with what value?         ReplacesNaN, positive infinity, and negative i...   \n",
       "What values are used to replace negative infini...  ReplacesNaN, positive infinity, and negative i...   \n",
       "What is the default value for negative infinity?    ReplacesNaN, positive infinity, and negative i...   \n",
       "What is the value to replace positive infinity ...  nan(Number,optional) – the value to replaceNaN...   \n",
       "...                                                                                               ...   \n",
       "What is the tensor of shape where*is zero or mo...  torch.linalg.inv()computes the inverse of a sq...   \n",
       "What is the tolerance value to determine when i...  torch.linalg.lstsq()computesA.pinv() @Bwith a\\...   \n",
       "What is the default value of atorch.Tensor?         See also torch.linalg.inv()computes the invers...   \n",
       "What computes the inverse of a square matrix?       See also torch.linalg.inv()computes the invers...   \n",
       "What is the tensor of shape(*, m, n)where*is ze...  torch.linalg.lstsq()computesA.pinv() @Bwith a\\...   \n",
       "\n",
       "                                                                                               source  \n",
       "What values are specified to replaceNaN, positi...  https://pytorch.org/docs/stable/generated/torc...  \n",
       "By default,NaN is replaced with what value?         https://pytorch.org/docs/stable/generated/torc...  \n",
       "What values are used to replace negative infini...  https://pytorch.org/docs/stable/generated/torc...  \n",
       "What is the default value for negative infinity?    https://pytorch.org/docs/stable/generated/torc...  \n",
       "What is the value to replace positive infinity ...  https://pytorch.org/docs/stable/generated/torc...  \n",
       "...                                                                                               ...  \n",
       "What is the tensor of shape where*is zero or mo...  https://pytorch.org/docs/stable/generated/torc...  \n",
       "What is the tolerance value to determine when i...  https://pytorch.org/docs/stable/generated/torc...  \n",
       "What is the default value of atorch.Tensor?         https://pytorch.org/docs/stable/generated/torc...  \n",
       "What computes the inverse of a square matrix?       https://pytorch.org/docs/stable/generated/torc...  \n",
       "What is the tensor of shape(*, m, n)where*is ze...  https://pytorch.org/docs/stable/generated/torc...  \n",
       "\n",
       "[1003 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>What values are specified to replaceNaN, positive infinity, and negative infinity values in input?</th>\n",
       "      <td>bynan,posinf, andneginf</td>\n",
       "      <td>What values are specified to replaceNaN, posit...</td>\n",
       "      <td>ReplacesNaN, positive infinity, and negative i...</td>\n",
       "      <td>https://pytorch.org/docs/stable/generated/torc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>By default,NaN is replaced with what value?</th>\n",
       "      <td>zero</td>\n",
       "      <td>By default,NaN is replaced with what value?</td>\n",
       "      <td>ReplacesNaN, positive infinity, and negative i...</td>\n",
       "      <td>https://pytorch.org/docs/stable/generated/torc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What values are used to replace negative infinity values in input?</th>\n",
       "      <td>bynan,posinf, andneginf</td>\n",
       "      <td>What values are used to replace negative infin...</td>\n",
       "      <td>ReplacesNaN, positive infinity, and negative i...</td>\n",
       "      <td>https://pytorch.org/docs/stable/generated/torc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is the default value for negative infinity?</th>\n",
       "      <td>the least finite value</td>\n",
       "      <td>What is the default value for negative infinity?</td>\n",
       "      <td>ReplacesNaN, positive infinity, and negative i...</td>\n",
       "      <td>https://pytorch.org/docs/stable/generated/torc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is the value to replace positive infinity values with?</th>\n",
       "      <td>posinf</td>\n",
       "      <td>What is the value to replace positive infinity...</td>\n",
       "      <td>nan(Number,optional) – the value to replaceNaN...</td>\n",
       "      <td>https://pytorch.org/docs/stable/generated/torc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is the tensor of shape where*is zero or more batch dimensions?</th>\n",
       "      <td>A(Tensor)</td>\n",
       "      <td>What is the tensor of shape where*is zero or m...</td>\n",
       "      <td>torch.linalg.inv()computes the inverse of a sq...</td>\n",
       "      <td>https://pytorch.org/docs/stable/generated/torc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is the tolerance value to determine when is a singular value zero?</th>\n",
       "      <td>rcond</td>\n",
       "      <td>What is the tolerance value to determine when ...</td>\n",
       "      <td>torch.linalg.lstsq()computesA.pinv() @Bwith a\\...</td>\n",
       "      <td>https://pytorch.org/docs/stable/generated/torc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is the default value of atorch.Tensor?</th>\n",
       "      <td>1e-15</td>\n",
       "      <td>What is the default value of atorch.Tensor?</td>\n",
       "      <td>See also torch.linalg.inv()computes the invers...</td>\n",
       "      <td>https://pytorch.org/docs/stable/generated/torc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What computes the inverse of a square matrix?</th>\n",
       "      <td>torch.linalg.inv()</td>\n",
       "      <td>What computes the inverse of a square matrix?</td>\n",
       "      <td>See also torch.linalg.inv()computes the invers...</td>\n",
       "      <td>https://pytorch.org/docs/stable/generated/torc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is the tensor of shape(*, m, n)where*is zero or more batch dimensions?</th>\n",
       "      <td>A(Tensor)</td>\n",
       "      <td>What is the tensor of shape(*, m, n)where*is z...</td>\n",
       "      <td>torch.linalg.lstsq()computesA.pinv() @Bwith a\\...</td>\n",
       "      <td>https://pytorch.org/docs/stable/generated/torc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f'device is {device}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "device is cpu\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data = 'data/nikhil_onlytextpytorch.json'\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 232k/232k [00:03<00:00, 65.1kB/s]\n",
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 16.7kB/s]\n",
      "Downloading: 100%|██████████| 466k/466k [00:01<00:00, 389kB/s]\n",
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 258kB/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def read_qna_file(input_file):\n",
    "    \"\"\"Read a  json file into a list and return data.\"\"\"\n",
    "    with open(input_file, \"r\", encoding='utf-8') as reader:\n",
    "        input_data = json.load(reader)[\"data\"]\n",
    "        return input_data\n",
    "\n",
    "def tokenize(input_text, tokenizer, device):\n",
    "    \"\"\"Tokenize the input text using tokenizer\"\"\"\n",
    "    tokens = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "# Add CLS and SEP tokens to the device\n",
    "def tokenize(input_text, tokenizer, device):\n",
    "    \"\"\"Add tokens requrired for BERT to the training data\"\"\"\n",
    "    ['CLS'] ['SEP']\n",
    "# Convert string into tokens and back\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1016"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print(len(data.keys()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1003\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(data, test_size=.2)\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "37",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pg/tbgv3_8n2kg77xkdv85jvcb00000gn/T/ipykernel_7020/2895683672.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/caps/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m     return list(chain.from_iterable((_safe_indexing(a, train),\n\u001b[0m\u001b[1;32m   2200\u001b[0m                                      _safe_indexing(a, test)) for a in arrays))\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/caps/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m     return list(chain.from_iterable((_safe_indexing(a, train),\n\u001b[0m\u001b[1;32m   2200\u001b[0m                                      _safe_indexing(a, test)) for a in arrays))\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/caps/lib/python3.8/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/caps/lib/python3.8/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_list_indexing\u001b[0;34m(X, key, key_dtype)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# key is a integer array-like of key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/caps/lib/python3.8/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# key is a integer array-like of key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 37"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "# val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "\n",
    "class qna_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
    "val_dataset = IMDbDataset(val_encodings, val_labels)\n",
    "test_dataset = IMDbDataset(test_encodings, test_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# Adding tokens\n",
    "\n",
    "\n",
    "doc_stride=''\n",
    "max_query_length = 100\n",
    "max_seq_length=100\n",
    "cls_token='[CLS]'\n",
    "sep_token='[SEP]'\n",
    "pad_token=0\n",
    "sequence_a_segment_id=0\n",
    "sequence_b_segment_id=1,\n",
    "cls_token_segment_id=0\n",
    "pad_token_segment_id=0,\n",
    "mask_padding_with_zero=True\n",
    "\n",
    "\n",
    "unique_id = 1000000000\n",
    "\n",
    "features = []\n",
    "\n",
    "query_tokens = tokenizer.tokenize(example.question_text)\n",
    "\n",
    "if len(query_tokens) > max_query_length:\n",
    "    query_tokens = query_tokens[0:max_query_length]\n",
    "\n",
    "    tok_to_orig_index = []\n",
    "    orig_to_tok_index = []\n",
    "    all_doc_tokens = []\n",
    "    for (i, token) in enumerate(example.doc_tokens):\n",
    "        orig_to_tok_index.append(len(all_doc_tokens))\n",
    "        sub_tokens = tokenizer.tokenize(token)\n",
    "        for sub_token in sub_tokens:\n",
    "            tok_to_orig_index.append(i)\n",
    "            all_doc_tokens.append(sub_token)\n",
    "\n",
    "    tok_start_position = None\n",
    "    tok_end_position = None\n",
    "    if is_training and example.is_impossible:\n",
    "        tok_start_position = -1\n",
    "        tok_end_position = -1\n",
    "    if is_training and not example.is_impossible:\n",
    "        tok_start_position = orig_to_tok_index[example.start_position]\n",
    "        if example.end_position < len(example.doc_tokens) - 1:\n",
    "            tok_end_position = orig_to_tok_index[example.end_position + 1] - 1\n",
    "        else:\n",
    "            tok_end_position = len(all_doc_tokens) - 1\n",
    "        (tok_start_position, tok_end_position) = _improve_answer_span(\n",
    "            all_doc_tokens, tok_start_position, tok_end_position, tokenizer,\n",
    "            example.orig_answer_text)\n",
    "\n",
    "    # The -3 accounts for [CLS], [SEP] and [SEP]\n",
    "    max_tokens_for_doc = max_seq_length - len(query_tokens) - 3\n",
    "\n",
    "    # We can have documents that are longer than the maximum sequence length.\n",
    "    # To deal with this we do a sliding window approach, where we take chunks\n",
    "    # of the up to our max length with a stride of `doc_stride`.\n",
    "    _DocSpan = collections.namedtuple(  # pylint: disable=invalid-name\n",
    "        \"DocSpan\", [\"start\", \"length\"])\n",
    "    doc_spans = []\n",
    "    start_offset = 0\n",
    "    while start_offset < len(all_doc_tokens):\n",
    "        length = len(all_doc_tokens) - start_offset\n",
    "        if length > max_tokens_for_doc:\n",
    "            length = max_tokens_for_doc\n",
    "        doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
    "        if start_offset + length == len(all_doc_tokens):\n",
    "            break\n",
    "        start_offset += min(length, doc_stride)\n",
    "\n",
    "    for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
    "        tokens = []\n",
    "        token_to_orig_map = {}\n",
    "        token_is_max_context = {}\n",
    "        segment_ids = []\n",
    "\n",
    "        # p_mask: mask with 1 for token than cannot be in the answer (0 for token which can be in an answer)\n",
    "        # Original TF implem also keep the classification token (set to 0) (not sure why...)\n",
    "        p_mask = []\n",
    "\n",
    "        # CLS token at the beginning\n",
    "        if not cls_token_at_end:\n",
    "            tokens.append(cls_token)\n",
    "            segment_ids.append(cls_token_segment_id)\n",
    "            p_mask.append(0)\n",
    "            cls_index = 0\n",
    "\n",
    "        # Query\n",
    "        for token in query_tokens:\n",
    "            tokens.append(token)\n",
    "            segment_ids.append(sequence_a_segment_id)\n",
    "            p_mask.append(1)\n",
    "\n",
    "        # SEP token\n",
    "        tokens.append(sep_token)\n",
    "        segment_ids.append(sequence_a_segment_id)\n",
    "        p_mask.append(1)\n",
    "\n",
    "        # Paragraph\n",
    "        for i in range(doc_span.length):\n",
    "            split_token_index = doc_span.start + i\n",
    "            token_to_orig_map[len(tokens)] = tok_to_orig_index[split_token_index]\n",
    "\n",
    "            is_max_context = _check_is_max_context(doc_spans, doc_span_index,\n",
    "                                                    split_token_index)\n",
    "            token_is_max_context[len(tokens)] = is_max_context\n",
    "            tokens.append(all_doc_tokens[split_token_index])\n",
    "            segment_ids.append(sequence_b_segment_id)\n",
    "            p_mask.append(0)\n",
    "        paragraph_len = doc_span.length\n",
    "\n",
    "        # SEP token\n",
    "        tokens.append(sep_token)\n",
    "        segment_ids.append(sequence_b_segment_id)\n",
    "        p_mask.append(1)\n",
    "\n",
    "        # CLS token at the end\n",
    "        if cls_token_at_end:\n",
    "            tokens.append(cls_token)\n",
    "            segment_ids.append(cls_token_segment_id)\n",
    "            p_mask.append(0)\n",
    "            cls_index = len(tokens) - 1  # Index of classification token\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(pad_token)\n",
    "            input_mask.append(0 if mask_padding_with_zero else 1)\n",
    "            segment_ids.append(pad_token_segment_id)\n",
    "            p_mask.append(1)\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        span_is_impossible = example.is_impossible\n",
    "        start_position = None\n",
    "        end_position = None\n",
    "        if is_training and not span_is_impossible:\n",
    "            # For training, if our document chunk does not contain an annotation\n",
    "            # we throw it out, since there is nothing to predict.\n",
    "            doc_start = doc_span.start\n",
    "            doc_end = doc_span.start + doc_span.length - 1\n",
    "            out_of_span = False\n",
    "            if not (tok_start_position >= doc_start and\n",
    "                    tok_end_position <= doc_end):\n",
    "                out_of_span = True\n",
    "            if out_of_span:\n",
    "                start_position = 0\n",
    "                end_position = 0\n",
    "                span_is_impossible = True\n",
    "            else:\n",
    "                doc_offset = len(query_tokens) + 2\n",
    "                start_position = tok_start_position - doc_start + doc_offset\n",
    "                end_position = tok_end_position - doc_start + doc_offset\n",
    "\n",
    "        if is_training and span_is_impossible:\n",
    "            start_position = cls_index\n",
    "            end_position = cls_index\n",
    "\n",
    "        if example_index < 20:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"unique_id: %s\" % (unique_id))\n",
    "            logger.info(\"example_index: %s\" % (example_index))\n",
    "            logger.info(\"doc_span_index: %s\" % (doc_span_index))\n",
    "            logger.info(\"tokens: %s\" % \" \".join(tokens))\n",
    "            logger.info(\"token_to_orig_map: %s\" % \" \".join([\n",
    "                \"%d:%d\" % (x, y) for (x, y) in token_to_orig_map.items()]))\n",
    "            logger.info(\"token_is_max_context: %s\" % \" \".join([\n",
    "                \"%d:%s\" % (x, y) for (x, y) in token_is_max_context.items()\n",
    "            ]))\n",
    "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\n",
    "                \"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "            logger.info(\n",
    "                \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "            if is_training and span_is_impossible:\n",
    "                logger.info(\"impossible example\")\n",
    "            if is_training and not span_is_impossible:\n",
    "                answer_text = \" \".join(tokens[start_position:(end_position + 1)])\n",
    "                logger.info(\"start_position: %d\" % (start_position))\n",
    "                logger.info(\"end_position: %d\" % (end_position))\n",
    "                logger.info(\n",
    "                    \"answer: %s\" % (answer_text))\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                unique_id=unique_id,\n",
    "                example_index=example_index,\n",
    "                doc_span_index=doc_span_index,\n",
    "                tokens=tokens,\n",
    "                token_to_orig_map=token_to_orig_map,\n",
    "                token_is_max_context=token_is_max_context,\n",
    "                input_ids=input_ids,\n",
    "                input_mask=input_mask,\n",
    "                segment_ids=segment_ids,\n",
    "                cls_index=cls_index,\n",
    "                p_mask=p_mask,\n",
    "                paragraph_len=paragraph_len,\n",
    "                start_position=start_position,\n",
    "                end_position=end_position,\n",
    "                is_impossible=span_is_impossible))\n",
    "        unique_id += 1\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('caps': conda)"
  },
  "interpreter": {
   "hash": "d964e81d6599016aee694e721ea343ca3a42c4f371ca966a53ff9f7507121df1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}