{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "  \n",
    "import json\n",
    "  \n",
    "  \n",
    "# JSON string\n",
    "\n",
    "  \n",
    "# deserializes into dict \n",
    "# and returns dict.\n",
    "# y = json.loads('../nikhil_onlytextpytorch.json')\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "# # JSON file\n",
    "f = open ('nikhil_onlytextpytorch.json', \"r\")\n",
    "  \n",
    "# Reading from file\n",
    "data = json.loads(f.read())\n",
    "  \n",
    "# Iterating through the json\n",
    "# list\n",
    "# for i in data['emp_details']:\n",
    "#     print(i)\n",
    "\n",
    "  \n",
    "# Closing file\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "len(data.values())\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def read_squad_examples(input_file, is_training, version_2_with_negative):\n",
    "    \"\"\"Read a SQuAD json file into a list of SquadExample.\"\"\"\n",
    "    with open(input_file, \"r\", encoding='utf-8') as reader:\n",
    "        input_data = json.load(reader)[\"data\"]\n",
    "\n",
    "    def is_whitespace(c):\n",
    "        if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    examples = []\n",
    "    for entry in input_data:\n",
    "\n",
    "        doc_tokens = []\n",
    "        char_to_word_offset = []\n",
    "        prev_is_whitespace = True\n",
    "        \n",
    "        if is_whitespace(c):\n",
    "            prev_is_whitespace = True\n",
    "        else:\n",
    "            if prev_is_whitespace:\n",
    "                doc_tokens.append(c)\n",
    "            else:\n",
    "                doc_tokens[-1] += c\n",
    "            prev_is_whitespace = False\n",
    "        char_to_word_offset.append(len(doc_tokens) - 1)\n",
    "\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                qas_id = qa[\"id\"]\n",
    "                question_text = qa[\"question\"]\n",
    "                start_position = None\n",
    "                end_position = None\n",
    "                orig_answer_text = None\n",
    "                is_impossible = False\n",
    "                if is_training:\n",
    "                    if version_2_with_negative:\n",
    "                        is_impossible = qa[\"is_impossible\"]\n",
    "                    if (len(qa[\"answers\"]) != 1) and (not is_impossible):\n",
    "                        raise ValueError(\n",
    "                            \"For training, each question should have exactly 1 answer.\")\n",
    "                    if not is_impossible:\n",
    "                        answer = qa[\"answers\"][0]\n",
    "                        orig_answer_text = answer[\"text\"]\n",
    "                        answer_offset = answer[\"answer_start\"]\n",
    "                        answer_length = len(orig_answer_text)\n",
    "                        start_position = char_to_word_offset[answer_offset]\n",
    "                        end_position = char_to_word_offset[answer_offset + answer_length - 1]\n",
    "                        # Only add answers where the text can be exactly recovered from the\n",
    "                        # document. If this CAN'T happen it's likely due to weird Unicode\n",
    "                        # stuff so we will just skip the example.\n",
    "                        #\n",
    "                        # Note that this means for training mode, every example is NOT\n",
    "                        # guaranteed to be preserved.\n",
    "                        actual_text = \" \".join(doc_tokens[start_position:(end_position + 1)])\n",
    "                        cleaned_answer_text = \" \".join(\n",
    "                            whitespace_tokenize(orig_answer_text))\n",
    "                        if actual_text.find(cleaned_answer_text) == -1:\n",
    "                            logger.warning(\"Could not find answer: '%s' vs. '%s'\",\n",
    "                                           actual_text, cleaned_answer_text)\n",
    "                            continue\n",
    "                    else:\n",
    "                        start_position = -1\n",
    "                        end_position = -1\n",
    "                        orig_answer_text = \"\"\n",
    "\n",
    "                example = SquadExample(\n",
    "                    qas_id=qas_id,\n",
    "                    question_text=question_text,\n",
    "                    doc_tokens=doc_tokens,\n",
    "                    orig_answer_text=orig_answer_text,\n",
    "                    start_position=start_position,\n",
    "                    end_position=end_position,\n",
    "                    is_impossible=is_impossible)\n",
    "                examples.append(example)\n",
    "    return examples\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1016"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('crawlers': conda)"
  },
  "interpreter": {
   "hash": "8faddf84061dc8509bf8ae110be406bb01c8c04077984943332ddbdbc3fab85c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}